{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0eba0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b3650",
   "metadata": {},
   "source": [
    "# Point cloud\n",
    "This tutorial demonstrates basci usage of a point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83a2ba",
   "metadata": {},
   "source": [
    "## Visualize point cloud\n",
    "The first part of the tutorial reads a point cloud and vuisualizes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcc1b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n",
      "PointCloud with 196133 points.\n",
      "[[0.65234375 0.84686458 2.37890625]\n",
      " [0.65234375 0.83984375 2.38430572]\n",
      " [0.66737998 0.83984375 2.37890625]\n",
      " ...\n",
      " [2.00839925 2.39453125 1.88671875]\n",
      " [2.00390625 2.39488506 1.88671875]\n",
      " [2.00390625 2.39453125 1.88793314]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "pcd = o3d.io.read_point_cloud(ply_point_cloud.path)\n",
    "print(pcd)\n",
    "print(np.asarray(pcd.points))\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192ba3a",
   "metadata": {},
   "source": [
    "```read_point_cloud``` reads a point cloud from a file. It tries to decode the file based on the extension name. For a list of supported file types, refer to File IO.\n",
    "\n",
    "```draw_geometries``` visualizes the point cloud. Use a mouse/trackpad to see the geometry from different view points.\n",
    "\n",
    "It looks like a dense surface, but it is actually a point cloud rendered as surfels. The GUI supports various keyboard functions. For instance, the - key reduces the size of the points (surfels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a3f19",
   "metadata": {},
   "source": [
    "## Voxel downsampling\n",
    "Voxel downsampling uses a regular voxel grid to create a uniformly downsampled point cloud from an input point cloud. It is often used as a pre-processing step for many point cloud processing tasks. The algorithm operates in two steps:\n",
    "1. Points are bucketed into voxels.\n",
    "2. Each occupied voxel generates exactly one point by averaging all points inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a03f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample the point cloud with a voxel of 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Downsample the point cloud with a voxel of 0.05\")\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "o3d.visualization.draw_geometries([downpcd],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29800751",
   "metadata": {},
   "source": [
    "## Vertex normal estimation\n",
    "Another basic operation for point cloud is point normal estimation. Press ```N``` to see point normals. The keys ```-``` and ```+``` can be used to control the length of the normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed5acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompute the normal of the downsampled point cloud\n"
     ]
    }
   ],
   "source": [
    "print(\"Recompute the normal of the downsampled point cloud\")\n",
    "downpcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "o3d.visualization.draw_geometries([downpcd],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
    "                                  point_show_normal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e86d90",
   "metadata": {},
   "source": [
    "```estimate_normals``` computes the normal for every point. The function finds adjacent points and calculates the principal axis of the adjacent points using covariance analysis.\n",
    "\n",
    "The function takes an instance of ```KDTreeSearchParamHybrid``` class as an argument. The two key arguments ```radius = 0.1``` and ```max_nn = 30``` specifies search radius and maximum nearest neighbor. It has 10cm of search radius, and only considers up to 30 neighbors to save computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6759ef9",
   "metadata": {},
   "source": [
    "<html><head>\n",
    "\n",
    "\n",
    "<!-- Load require.js. Delete this if your page already loads require.js -->\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js\" integrity=\"sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=\" crossorigin=\"anonymous\"></script>\n",
    "<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n",
    "<script type=\"application/vnd.jupyter.widget-state+json\">\n",
    "{\n",
    "    \"version_major\": 2,\n",
    "    \"version_minor\": 0,\n",
    "    \"state\": {}\n",
    "}\n",
    "</script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "    The covariance analysis algorithm produces two opposite directions as normal candidates. Without knowing the global structure of the geometry, both can be correct. This is known as the normal orientation problem. Open3D tries to orient the normal to align with the original normal if it exists. Otherwise, Open3D does a random guess. Further orientation functions such as orient_normals_to_align_with_direction and orient_normals_towards_camera_location need to be called if the orientation is a concern.\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665608f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
